{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob \n",
    "\n",
    "paths = glob('/Users/VoThinhPhat/Desktop/chatKPT-2024-AIC-HCMC/data/batch1/keyframes/keyframes_L05/L05_V010/*.jpg')\n",
    "paths.sort()\n",
    "\n",
    "for i in range(0, len(paths)):\n",
    "    img_name = paths[i][:-4].rsplit(os.sep, 1)[-1]\n",
    "    if (img_name == \"21419\"):\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'06:51:12',\n",
       " '160',\n",
       " 'bisan truot bang giang sinh',\n",
       " 'dde',\n",
       " 'hd',\n",
       " 'htv9',\n",
       " 'lay nguoi nuoc ngoai lua dao tinh cam de lay tien',\n",
       " 'rokyns',\n",
       " 'toa an tai anh phong toa tai san cua 2ng',\n",
       " 'trong ngoi nha tho co',\n",
       " 'uwofficie',\n",
       " 'voorsint',\n",
       " 'www'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "def remove_diacritics_and_punctuation(s):\n",
    "    \"\"\"\n",
    "    Loại bỏ dấu tiếng Việt và ký tự đặc biệt như dấu nháy đơn.\n",
    "    \"\"\"\n",
    "    s = s.replace(\"'\", \"\")\n",
    "    nkfd_form = unicodedata.normalize('NFKD', s)\n",
    "    return ''.join([c for c in nkfd_form if not unicodedata.combining(c)])\n",
    "\n",
    "\n",
    "file_path = '/Users/VoThinhPhat/Desktop/chatKPT-2024-AIC-HCMC/data/batch1/ocr/L05_V010.bin'\n",
    "if os.path.getsize(file_path) > 0:\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "else:\n",
    "    data = []\n",
    "\n",
    "for i, sset in enumerate(data):\n",
    "    # Tạo một set mới với các phần tử đã được xử lý\n",
    "    new_set = {remove_diacritics_and_punctuation(s) for s in sset}\n",
    "    # Gán set mới vào vị trí tương ứng trong data\n",
    "    data[i] = new_set\n",
    "\n",
    "data[658]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Sự tương đồng (fuzzy): 't rat yeu cu' và 'a' với tỉ lệ 19.999999999999996%\n",
      "False\n",
      "Sự tương đồng (fuzzy): 'toira yecau' và 'a' với tỉ lệ 18.181818181818176%\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from rapidfuzz import fuzz\n",
    "\n",
    "def is_similar_two_words(a, b, threshold=70):\n",
    "    a_lower = a.lower().replace(\" \", \"\")\n",
    "    b_lower = b.lower().replace(\" \", \"\")\n",
    "    \n",
    "    if a_lower in b_lower:\n",
    "        return True\n",
    "    \n",
    "    similarity_score = fuzz.token_sort_ratio(a_lower, b_lower)\n",
    "    \n",
    "    if similarity_score >= threshold:\n",
    "        return True\n",
    "    \n",
    "    print(f\"Sự tương đồng (fuzzy): '{a}' và '{b}' với tỉ lệ {similarity_score}%\")\n",
    "    return False\n",
    "\n",
    "text = \"a\"\n",
    "\n",
    "t1 = \"a\"\n",
    "t2 = \"t rat yeu cu\" \n",
    "t3 = \"toira yecau\"\n",
    "\n",
    "print(is_similar_two_words(t1, text))\n",
    "print(is_similar_two_words(t2, text))\n",
    "print(is_similar_two_words(t3, text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
