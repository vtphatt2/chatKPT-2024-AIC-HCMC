{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset name\n",
    "name = \"AIC_2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████| 106589/106589 [14.1s elapsed, 0s remaining, 7.4K samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# run in about 15 seconds\n",
    "if fo.dataset_exists(name):\n",
    "    fo.delete_dataset(name)\n",
    "    \n",
    "dataset = fo.Dataset.from_images_dir(\n",
    "    name=name, \n",
    "    images_dir=\"../data\", \n",
    "    recursive=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    }
   ],
   "source": [
    "# if you want to automatically open the browser, just uncomment session.open_tab()\n",
    "# or you can visit directly : http://localhost:5151/datasets/AIC_2024\n",
    "\n",
    "session = fo.launch_app(dataset, auto=False)\n",
    "# session.open_tab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Sample: {\n",
      "    'id': '66dc8eaec51388152a849c3f',\n",
      "    'media_type': 'image',\n",
      "    'filepath': 'C:\\\\Users\\\\LENOVO\\\\Desktop\\\\chatKPT-2024-AIC-HCMC\\\\data\\\\batch1\\\\keyframes\\\\keyframes_L01\\\\L01_V001\\\\001.jpg',\n",
      "    'tags': [],\n",
      "    'metadata': None,\n",
      "}>\n"
     ]
    }
   ],
   "source": [
    "print(dataset.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m unique_videos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m----> 4\u001b[0m     tmp, sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m], sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeyframe_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilepath\u001b[39m\u001b[38;5;124m'\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      5\u001b[0m     sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m tmp\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m4\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m      6\u001b[0m     unique_videos\u001b[38;5;241m.\u001b[39madd(sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "# run in about 36 seconds\n",
    "unique_videos = set()\n",
    "for sample in dataset:\n",
    "    tmp, sample['video'], sample['keyframe_id'] = sample['filepath'][:-4].rsplit('/', 2)\n",
    "    sample['batch'] = tmp.rsplit('/', 4)[-3]\n",
    "    unique_videos.add(sample['video'])\n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map keyframes_id into corresponding frame_id\n",
    "# run in nearly 40 seconds\n",
    "video_frameid_dict = {}\n",
    "for b in [1, 2, 3]:\n",
    "    for video in unique_videos:\n",
    "        filepath = f\"../data/batch{b}/map-keyframes/{video}.csv\"\n",
    "        if os.path.exists(filepath):\n",
    "            a = pd.read_csv(filepath)\n",
    "            video_frameid_dict[video] = a['frame_idx']\n",
    "\n",
    "for sample in dataset:\n",
    "    sample['frame_id'] = video_frameid_dict[sample['video']].iloc[int(sample['keyframe_id']) - 1]\n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Sample: {\n",
      "    'id': '66d20c8f06d76b7fd439824f',\n",
      "    'media_type': 'image',\n",
      "    'filepath': '/Users/VoThinhPhat/Desktop/chatKPT-2024-AIC-HCMC/data/batch1/keyframes/keyframes_L01/L01_V001/001.jpg',\n",
      "    'tags': [],\n",
      "    'metadata': None,\n",
      "    'video': 'L01_V001',\n",
      "    'keyframe_id': '001',\n",
      "    'batch': 'batch1',\n",
      "    'frame_id': 0,\n",
      "}>\n"
     ]
    }
   ],
   "source": [
    "print(dataset.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fiftyone.brain.internal.core.sklearn.SklearnSimilarityIndex at 0x29cc818b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load precomputed clip embeddings\n",
    "# run in about 1 minutes\n",
    "\n",
    "video_keyframe_dict = {}\n",
    "all_keyframe = glob('../data/batch*/keyframes/*/*/*.jpg')\n",
    "\n",
    "for kf in all_keyframe:\n",
    "    _, vid, kf = kf[:-4].rsplit('/',2)\n",
    "    if vid not in video_keyframe_dict.keys():\n",
    "        video_keyframe_dict[vid] = [kf]\n",
    "    else:\n",
    "        video_keyframe_dict[vid].append(kf)\n",
    "\n",
    "for k,v in video_keyframe_dict.items():\n",
    "    video_keyframe_dict[k] = sorted(v)\n",
    "\n",
    "embedding_dict = {}\n",
    "for j in [1, 2, 3]:\n",
    "    for video in unique_videos:\n",
    "        clip_path = f\"../data/batch{j}/clip-features-32/{video}.npy\"\n",
    "        if os.path.exists(clip_path):\n",
    "            a = np.load(clip_path)\n",
    "            embedding_dict[video] = {}\n",
    "            for i, k in enumerate(video_keyframe_dict[video]):\n",
    "                embedding_dict[video][k] = a[i]\n",
    "\n",
    "clip_embeddings = []\n",
    "for sample in dataset:\n",
    "    clip_embedding = embedding_dict[sample['video']][sample['keyframe_id']]\n",
    "    clip_embeddings.append(clip_embedding)\n",
    "\n",
    "if dataset.has_brain_run(\"img_sim_clip\"):\n",
    "    dataset.delete_brain_run(\"img_sim_clip\")\n",
    "fob.compute_similarity(\n",
    "    dataset,\n",
    "    model=\"clip-vit-base32-torch\",     \n",
    "    embeddings=clip_embeddings,         \n",
    "    brain_key=\"img_sim_clip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../export' already exists; export will be merged with existing files\n",
      "Exporting samples...\n",
      " 100% |██████████████| 106589/106589 [1.8s elapsed, 0s remaining, 69.8K docs/s]      \n"
     ]
    }
   ],
   "source": [
    "# export the entire dataset into disk, see reload.ipynb for loading\n",
    "dataset.export(\n",
    "    export_dir=\"../export\",\n",
    "    dataset_type=fo.types.FiftyOneDataset,\n",
    "    export_media=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
